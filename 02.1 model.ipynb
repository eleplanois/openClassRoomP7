{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "animated-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "several-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_as_category = True\n",
    "\n",
    "def one_hot_encoder(df, nan_as_category=True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns\n",
    "\n",
    "def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
    "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n",
    "                               for e in agg_df.columns.tolist()])\n",
    "    return agg_df.reset_index()\n",
    "\n",
    "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n",
    "    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n",
    "\n",
    "def do_sum(dataframe, group_cols, counted, agg_name):\n",
    "    gp = dataframe[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(columns={counted: agg_name})\n",
    "    dataframe = dataframe.merge(gp, on=group_cols, how='left')\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "victorian-ridge",
   "metadata": {
    "papermill": {
     "duration": 0.045598,
     "end_time": "2021-05-04T15:38:40.187389",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.141791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def application():\n",
    "    df = pd.read_csv(r'dataset/application_train.csv')\n",
    "\n",
    "    # general cleaning procedures\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    df = df[df['AMT_INCOME_TOTAL'] < 20000000] # remove a outlier 117M\n",
    "\n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True) # set null value\n",
    "    df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True) # set null value\n",
    "\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    \n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "\n",
    "    # Flag_document features - count and kurtosis\n",
    "    docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "    df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "    df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n",
    "\n",
    "    def get_age_label(days_birth):\n",
    "        \"\"\" Return the age group label (int). \"\"\"\n",
    "        age_years = -days_birth / 365\n",
    "        if age_years < 27: return 1\n",
    "        elif age_years < 40: return 2\n",
    "        elif age_years < 50: return 3\n",
    "        elif age_years < 65: return 4\n",
    "        elif age_years < 99: return 5\n",
    "        else: return 0\n",
    "    # Categorical age - based on target=1 plot\n",
    "    df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))\n",
    "\n",
    "    # New features based on External sources\n",
    "    df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n",
    "    np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "    for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
    "        feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n",
    "        df[feature_name] = eval('np.{}'.format(function_name))(\n",
    "            df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)\n",
    "\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "    # Credit ratios\n",
    "    df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    \n",
    "    # Income ratios\n",
    "    df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "    df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']\n",
    "    \n",
    "    # Time ratios\n",
    "    df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "    df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "\n",
    "    # EXT_SOURCE_X FEATURE\n",
    "    df['APPS_EXT_SOURCE_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
    "    df['APPS_EXT_SOURCE_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
    "    df['APPS_EXT_SOURCE_STD'] = df['APPS_EXT_SOURCE_STD'].fillna(df['APPS_EXT_SOURCE_STD'].mean())\n",
    "    df['APP_SCORE1_TO_BIRTH_RATIO'] = df['EXT_SOURCE_1'] / (df['DAYS_BIRTH'] / 365.25)\n",
    "    df['APP_SCORE2_TO_BIRTH_RATIO'] = df['EXT_SOURCE_2'] / (df['DAYS_BIRTH'] / 365.25)\n",
    "    df['APP_SCORE3_TO_BIRTH_RATIO'] = df['EXT_SOURCE_3'] / (df['DAYS_BIRTH'] / 365.25)\n",
    "    df['APP_SCORE1_TO_EMPLOY_RATIO'] = df['EXT_SOURCE_1'] / (df['DAYS_EMPLOYED'] / 365.25)\n",
    "    df['APP_EXT_SOURCE_2*EXT_SOURCE_3*DAYS_BIRTH'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['DAYS_BIRTH']\n",
    "    df['APP_SCORE1_TO_FAM_CNT_RATIO'] = df['EXT_SOURCE_1'] / df['CNT_FAM_MEMBERS']\n",
    "    df['APP_SCORE1_TO_GOODS_RATIO'] = df['EXT_SOURCE_1'] / df['AMT_GOODS_PRICE']\n",
    "    df['APP_SCORE1_TO_CREDIT_RATIO'] = df['EXT_SOURCE_1'] / df['AMT_CREDIT']\n",
    "    df['APP_SCORE1_TO_SCORE2_RATIO'] = df['EXT_SOURCE_1'] / df['EXT_SOURCE_2']\n",
    "    df['APP_SCORE1_TO_SCORE3_RATIO'] = df['EXT_SOURCE_1'] / df['EXT_SOURCE_3']\n",
    "    df['APP_SCORE2_TO_CREDIT_RATIO'] = df['EXT_SOURCE_2'] / df['AMT_CREDIT']\n",
    "    df['APP_SCORE2_TO_REGION_RATING_RATIO'] = df['EXT_SOURCE_2'] / df['REGION_RATING_CLIENT']\n",
    "    df['APP_SCORE2_TO_CITY_RATING_RATIO'] = df['EXT_SOURCE_2'] / df['REGION_RATING_CLIENT_W_CITY']\n",
    "    df['APP_SCORE2_TO_POP_RATIO'] = df['EXT_SOURCE_2'] / df['REGION_POPULATION_RELATIVE']\n",
    "    df['APP_SCORE2_TO_PHONE_CHANGE_RATIO'] = df['EXT_SOURCE_2'] / df['DAYS_LAST_PHONE_CHANGE']\n",
    "    df['APP_EXT_SOURCE_1*EXT_SOURCE_2'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2']\n",
    "    df['APP_EXT_SOURCE_1*EXT_SOURCE_3'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_3']\n",
    "    df['APP_EXT_SOURCE_2*EXT_SOURCE_3'] = df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['APP_EXT_SOURCE_1*DAYS_EMPLOYED'] = df['EXT_SOURCE_1'] * df['DAYS_EMPLOYED']\n",
    "    df['APP_EXT_SOURCE_2*DAYS_EMPLOYED'] = df['EXT_SOURCE_2'] * df['DAYS_EMPLOYED']\n",
    "    df['APP_EXT_SOURCE_3*DAYS_EMPLOYED'] = df['EXT_SOURCE_3'] * df['DAYS_EMPLOYED']\n",
    "\n",
    "    # AMT_INCOME_TOTAL : income\n",
    "    # CNT_FAM_MEMBERS  : the number of family members\n",
    "    df['APPS_GOODS_INCOME_RATIO'] = df['AMT_GOODS_PRICE'] / df['AMT_INCOME_TOTAL']\n",
    "    df['APPS_CNT_FAM_INCOME_RATIO'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    \n",
    "    # DAYS_BIRTH : Client's age in days at the time of application\n",
    "    # DAYS_EMPLOYED : How many days before the application the person started current employment\n",
    "    df['APPS_INCOME_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "\n",
    "    # other feature from better than 0.8\n",
    "    df['CREDIT_TO_GOODS_RATIO_2'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    df['APP_AMT_INCOME_TOTAL_12_AMT_ANNUITY_ratio'] = df['AMT_INCOME_TOTAL'] / 12. - df['AMT_ANNUITY']\n",
    "    df['APP_INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "    df['APP_DAYS_LAST_PHONE_CHANGE_DAYS_EMPLOYED_ratio'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n",
    "    df['APP_DAYS_EMPLOYED_DAYS_BIRTH_diff'] = df['DAYS_EMPLOYED'] - df['DAYS_BIRTH']\n",
    "\n",
    "    print('\"Application_Train_Test\" final shape:', df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "included-establishment",
   "metadata": {
    "papermill": {
     "duration": 0.038152,
     "end_time": "2021-05-04T15:38:40.238153",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.200001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bureau_bb():\n",
    "    bureau = pd.read_csv(r'dataset/bureau.csv')\n",
    "    bb = pd.read_csv(r'dataset/bureau_balance.csv')\n",
    "\n",
    "    # Credit duration and credit/account end date difference\n",
    "    bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    \n",
    "    # Credit to debt ratio and difference\n",
    "    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']\n",
    "    bureau['BUREAU_CREDIT_FACT_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    bureau['BUREAU_CREDIT_ENDDATE_DIFF'] = bureau['DAYS_CREDIT'] - bureau['DAYS_CREDIT_ENDDATE']\n",
    "    bureau['BUREAU_CREDIT_DEBT_RATIO'] = bureau['AMT_CREDIT_SUM_DEBT'] / bureau['AMT_CREDIT_SUM']\n",
    "\n",
    "    # CREDIT_DAY_OVERDUE :\n",
    "    bureau['BUREAU_IS_DPD'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    bureau['BUREAU_IS_DPD_OVER120'] = bureau['CREDIT_DAY_OVERDUE'].apply(lambda x: 1 if x > 120 else 0)\n",
    "\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "\n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size', 'mean']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "\n",
    "    #Status of Credit Bureau loan during the month\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "\n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean', 'min'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean', 'max', 'sum'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_ANNUITY': ['max', 'mean', 'sum'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'MONTHS_BALANCE_MIN': ['min'],\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "        'SK_ID_BUREAU': ['count'],\n",
    "        'DAYS_ENDDATE_FACT': ['min', 'max', 'mean'],\n",
    "        'ENDDATE_DIF': ['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_FACT_DIFF': ['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_ENDDATE_DIFF': ['min', 'max', 'mean'],\n",
    "        'BUREAU_CREDIT_DEBT_RATIO': ['min', 'max', 'mean'],\n",
    "        'DEBT_CREDIT_DIFF': ['min', 'max', 'mean'],\n",
    "        'BUREAU_IS_DPD': ['mean', 'sum'],\n",
    "        'BUREAU_IS_DPD_OVER120': ['mean', 'sum']\n",
    "        }\n",
    "\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    print('\"Bureau/Bureau Balance\" final shape:', bureau_agg.shape)\n",
    "    return bureau_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "covered-hepatitis",
   "metadata": {
    "papermill": {
     "duration": 0.035905,
     "end_time": "2021-05-04T15:38:40.286660",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.250755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def previous_application():\n",
    "    prev = pd.read_csv(r'dataset/previous_application.csv')\n",
    "\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category=True)\n",
    "\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "\n",
    "    # Feature engineering: ratios and difference\n",
    "    prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "    prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT'] / prev['AMT_ANNUITY']\n",
    "    prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] / prev['AMT_CREDIT']\n",
    "\n",
    "    # Interest ratio on previous application (simplified)\n",
    "    total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "    prev['SIMPLE_INTERESTS'] = (total_payment / prev['AMT_CREDIT'] - 1) / prev['CNT_PAYMENT']\n",
    "\n",
    "    # Days last due difference (scheduled x done)\n",
    "    prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "\n",
    "    # from off\n",
    "    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n",
    "    prev['PREV_ANNUITY_APPL_RATIO'] = prev['AMT_ANNUITY']/prev['AMT_APPLICATION']\n",
    "    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE'] / prev['AMT_APPLICATION']\n",
    "\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean', 'sum'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean', 'sum'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "        'SK_ID_PREV': ['nunique'],\n",
    "        'DAYS_TERMINATION': ['max'],\n",
    "        'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "        'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'sum'],\n",
    "        'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n",
    "        'PREV_GOODS_DIFF': ['mean', 'max', 'sum'],\n",
    "        'PREV_GOODS_APPL_RATIO': ['mean', 'max'],\n",
    "        'DAYS_LAST_DUE_DIFF': ['mean', 'max', 'sum'],\n",
    "        'SIMPLE_INTERESTS': ['mean', 'max']\n",
    "    }\n",
    "\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "\n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    print('\"Previous Applications\" final shape:', prev_agg.shape)\n",
    "    return prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hungarian-peeing",
   "metadata": {
    "papermill": {
     "duration": 0.035205,
     "end_time": "2021-05-04T15:38:40.334464",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.299259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_cash():\n",
    "    pos = pd.read_csv(r'dataset/POS_CASH_balance.csv')\n",
    "\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category=True)\n",
    "\n",
    "    # Flag months with late payment\n",
    "    pos['LATE_PAYMENT'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    pos['POS_IS_DPD'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0) # <-- same with ['LATE_PAYMENT']\n",
    "    pos['POS_IS_DPD_UNDER_120'] = pos['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    pos['POS_IS_DPD_OVER_120'] = pos['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size', 'min'],\n",
    "        'SK_DPD': ['max', 'mean', 'sum', 'var', 'min'],\n",
    "        'SK_DPD_DEF': ['max', 'mean', 'sum'],\n",
    "        'SK_ID_PREV': ['nunique'],\n",
    "        'LATE_PAYMENT': ['mean'],\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'CNT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'CNT_INSTALMENT_FUTURE': ['min', 'max', 'mean', 'sum'],\n",
    "        'POS_IS_DPD': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'POS_IS_DPD_OVER_120': ['mean', 'sum'],\n",
    "    }\n",
    "\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "\n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "\n",
    "\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.groupby('SK_ID_PREV')\n",
    "    df_pos = pd.DataFrame()\n",
    "    df_pos['SK_ID_CURR'] = gp['SK_ID_CURR'].first()\n",
    "    df_pos['MONTHS_BALANCE_MAX'] = gp['MONTHS_BALANCE'].max()\n",
    "\n",
    "    # Percentage of previous loans completed and completed before initial term\n",
    "    df_pos['POS_LOAN_COMPLETED_MEAN'] = gp['NAME_CONTRACT_STATUS_Completed'].mean()\n",
    "    df_pos['POS_COMPLETED_BEFORE_MEAN'] = gp['CNT_INSTALMENT'].first() - gp['CNT_INSTALMENT'].last()\n",
    "    df_pos['POS_COMPLETED_BEFORE_MEAN'] = df_pos.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0 \\\n",
    "                                                                      and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n",
    "    # Number of remaining installments (future installments) and percentage from total\n",
    "    df_pos['POS_REMAINING_INSTALMENTS'] = gp['CNT_INSTALMENT_FUTURE'].last()\n",
    "    df_pos['POS_REMAINING_INSTALMENTS_RATIO'] = gp['CNT_INSTALMENT_FUTURE'].last()/gp['CNT_INSTALMENT'].last()\n",
    "\n",
    "    # Group by SK_ID_CURR and merge\n",
    "    df_gp = df_pos.groupby('SK_ID_CURR').sum().reset_index()\n",
    "    df_gp.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace= True)\n",
    "    pos_agg = pd.merge(pos_agg, df_gp, on= 'SK_ID_CURR', how= 'left')\n",
    "\n",
    "    # Percentage of late payments for the 3 most recent applications\n",
    "    pos = do_sum(pos, ['SK_ID_PREV'], 'LATE_PAYMENT', 'LATE_PAYMENT_SUM')\n",
    "\n",
    "    # Last month of each application\n",
    "    last_month_df = pos.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "\n",
    "    # Most recent applications (last 3)\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.iloc[last_month_df].groupby('SK_ID_CURR').tail(3)\n",
    "    gp_mean = gp.groupby('SK_ID_CURR').mean().reset_index()\n",
    "    pos_agg = pd.merge(pos_agg, gp_mean[['SK_ID_CURR', 'LATE_PAYMENT_SUM']], on='SK_ID_CURR', how='left')\n",
    "\n",
    "    print('\"Pos-Cash\" balance final shape:', pos_agg.shape) \n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "grand-flood",
   "metadata": {
    "papermill": {
     "duration": 0.039716,
     "end_time": "2021-05-04T15:38:40.387171",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.347455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def installment():\n",
    "    ins = pd.read_csv(r'dataset/installments_payments.csv')\n",
    "\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category=True)\n",
    "\n",
    "    # Group payments and get Payment difference\n",
    "    ins = do_sum(ins, ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'], 'AMT_PAYMENT', 'AMT_PAYMENT_GROUPED')\n",
    "    ins['PAYMENT_DIFFERENCE'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT_GROUPED']\n",
    "    ins['PAYMENT_RATIO'] = ins['AMT_INSTALMENT'] / ins['AMT_PAYMENT_GROUPED']\n",
    "    ins['PAID_OVER_AMOUNT'] = ins['AMT_PAYMENT'] - ins['AMT_INSTALMENT']\n",
    "    ins['PAID_OVER'] = (ins['PAID_OVER_AMOUNT'] > 0).astype(int)\n",
    "\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD_diff'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD_diff'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD_diff'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD_diff'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    # Flag late payment\n",
    "    ins['LATE_PAYMENT'] = ins['DBD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    ins['INSTALMENT_PAYMENT_RATIO'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['LATE_PAYMENT_RATIO'] = ins.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n",
    "\n",
    "    # Flag late payments that have a significant amount\n",
    "    ins['SIGNIFICANT_LATE_PAYMENT'] = ins['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n",
    "    \n",
    "    # Flag k threshold late payments\n",
    "    ins['DPD_7'] = ins['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "    ins['DPD_15'] = ins['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n",
    "\n",
    "    ins['INS_IS_DPD_UNDER_120'] = ins['DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    ins['INS_IS_DPD_OVER_120'] = ins['DPD'].apply(lambda x: 1 if (x >= 120) else 0)\n",
    "\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum', 'var'],\n",
    "        'DBD': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum', 'min'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum', 'min'],\n",
    "        'SK_ID_PREV': ['size', 'nunique'],\n",
    "        'PAYMENT_DIFFERENCE': ['mean'],\n",
    "        'PAYMENT_RATIO': ['mean', 'max'],\n",
    "        'LATE_PAYMENT': ['mean', 'sum'],\n",
    "        'SIGNIFICANT_LATE_PAYMENT': ['mean', 'sum'],\n",
    "        'LATE_PAYMENT_RATIO': ['mean'],\n",
    "        'DPD_7': ['mean'],\n",
    "        'DPD_15': ['mean'],\n",
    "        'PAID_OVER': ['mean'],\n",
    "        'DPD_diff':['mean', 'min', 'max'],\n",
    "        'DBD_diff':['mean', 'min', 'max'],\n",
    "        'DAYS_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_120': ['mean', 'sum']\n",
    "    }\n",
    "\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    # from oof (DAYS_ENTRY_PAYMENT)\n",
    "    cond_day = ins['DAYS_ENTRY_PAYMENT'] >= -365\n",
    "    ins_d365_grp = ins[cond_day].groupby('SK_ID_CURR')\n",
    "    ins_d365_agg_dict = {\n",
    "        'SK_ID_CURR': ['count'],\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['mean', 'max', 'sum'],\n",
    "        'DAYS_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_INSTALMENT': ['mean', 'max', 'sum'],\n",
    "        'AMT_PAYMENT': ['mean', 'max', 'sum'],\n",
    "        'PAYMENT_DIFF': ['mean', 'min', 'max', 'sum'],\n",
    "        'PAYMENT_PERC': ['mean', 'max'],\n",
    "        'DPD_diff': ['mean', 'min', 'max'],\n",
    "        'DPD': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'INS_IS_DPD_OVER_120': ['mean', 'sum']}\n",
    "\n",
    "    ins_d365_agg = ins_d365_grp.agg(ins_d365_agg_dict)\n",
    "    ins_d365_agg.columns = ['INS_D365' + ('_').join(column).upper() for column in ins_d365_agg.columns.ravel()]\n",
    "\n",
    "    ins_agg = ins_agg.merge(ins_d365_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    print('\"Installments Payments\" final shape:', ins_agg.shape)\n",
    "    return ins_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hydraulic-equipment",
   "metadata": {
    "papermill": {
     "duration": 0.032819,
     "end_time": "2021-05-04T15:38:40.433176",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.400357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def credit_card():    \n",
    "    cc = pd.read_csv(r'dataset/credit_card_balance.csv')\n",
    "\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=True)\n",
    "\n",
    "    # Amount used from limit\n",
    "    cc['LIMIT_USE'] = cc['AMT_BALANCE'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # Current payment / Min payment\n",
    "    cc['PAYMENT_DIV_MIN'] = cc['AMT_PAYMENT_CURRENT'] / cc['AMT_INST_MIN_REGULARITY']\n",
    "    # Late payment <-- 'CARD_IS_DPD'\n",
    "    cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # How much drawing of limit\n",
    "    cc['DRAWING_LIMIT_RATIO'] = cc['AMT_DRAWINGS_ATM_CURRENT'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "\n",
    "    cc['CARD_IS_DPD_UNDER_120'] = cc['SK_DPD'].apply(lambda x: 1 if (x > 0) & (x < 120) else 0)\n",
    "    cc['CARD_IS_DPD_OVER_120'] = cc['SK_DPD'].apply(lambda x: 1 if x >= 120 else 0)\n",
    "\n",
    "    # General aggregations\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    # Last month balance of each credit card application\n",
    "    last_ids = cc.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    last_months_df = cc[cc.index.isin(last_ids)]\n",
    "    cc_agg = group_and_merge(last_months_df,cc_agg,'CC_LAST_', {'AMT_BALANCE': ['mean', 'max']})\n",
    "\n",
    "    CREDIT_CARD_TIME_AGG = {\n",
    "        'AMT_BALANCE': ['mean', 'max'],\n",
    "        'LIMIT_USE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL':['max'],\n",
    "        'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
    "        'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
    "        'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
    "        'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
    "        'AMT_PAYMENT_TOTAL_CURRENT': ['max','sum'],\n",
    "        'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
    "        'CNT_DRAWINGS_ATM_CURRENT': ['max','sum', 'mean'],\n",
    "        'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "        'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
    "        'SK_DPD': ['mean', 'max', 'sum'],\n",
    "        'LIMIT_USE': ['min', 'max'],\n",
    "        'DRAWING_LIMIT_RATIO': ['min', 'max'],\n",
    "        'LATE_PAYMENT': ['mean', 'sum'],\n",
    "        'CARD_IS_DPD_UNDER_120': ['mean', 'sum'],\n",
    "        'CARD_IS_DPD_OVER_120': ['mean', 'sum']\n",
    "    }\n",
    "\n",
    "    for months in [12, 24, 48]:\n",
    "        cc_prev_id = cc[cc['MONTHS_BALANCE'] >= -months]['SK_ID_PREV'].unique()\n",
    "        cc_recent = cc[cc['SK_ID_PREV'].isin(cc_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        cc_agg = group_and_merge(cc_recent, cc_agg, prefix, CREDIT_CARD_TIME_AGG)\n",
    "\n",
    "\n",
    "    print('\"Credit Card Balance\" final shape:', cc_agg.shape)\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-boundary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-balloon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-technology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "written-hormone",
   "metadata": {
    "papermill": {
     "duration": 18922.809903,
     "end_time": "2021-05-04T20:54:03.343997",
     "exception": false,
     "start_time": "2021-05-04T15:38:40.534094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Application_Train_Test\" final shape: (307506, 308)\n",
      "\"Bureau/Bureau Balance\" final shape: (305811, 200)\n",
      "--=> df after merge with bureau: (307506, 508)\n"
     ]
    }
   ],
   "source": [
    "df = application()\n",
    "df = df.merge(bureau_bb(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with bureau:', df.shape)\n",
    "df = df.merge(previous_application(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with previous application:', df.shape)\n",
    "df = df.merge(pos_cash(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with pos cash :', df.shape)\n",
    "df = df.merge(installment(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with installments:', df.shape)\n",
    "df = df.merge(credit_card(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with credit card:', df.shape)\n",
    "#df = data_post_processing(df)\n",
    "#print('='*50, '\\n')\n",
    "#print('---=> df final shape:', df.shape, ' <=---', '\\n')\n",
    "#print('=' * 50)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "billion-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Previous Applications\" final shape: (338857, 321)\n",
      "--=> df after merge with previous application: (307506, 829)\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(previous_application(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with previous application:', df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sexual-forth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Pos-Cash\" balance final shape: (337252, 46)\n",
      "--=> df after merge with pos cash : (307506, 874)\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(pos_cash(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with pos cash :', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wrong-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-2704635bfa81>:90: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  ins_d365_agg.columns = ['INS_D365' + ('_').join(column).upper() for column in ins_d365_agg.columns.ravel()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Installments Payments\" final shape: (339587, 85)\n",
      "--=> df after merge with installments: (307506, 959)\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(installment(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with installments:', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "combined-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Credit Card Balance\" final shape: (103558, 284)\n",
      "--=> df after merge with credit card: (307506, 1242)\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(credit_card(), how='left', on='SK_ID_CURR')\n",
    "print('--=> df after merge with credit card:', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proprietary-ethernet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>CLOSED_BUREAU_CREDIT_DEBT_RATIO_MIN</th>\n",
       "      <th>CLOSED_BUREAU_CREDIT_DEBT_RATIO_MAX</th>\n",
       "      <th>CLOSED_BUREAU_CREDIT_DEBT_RATIO_MEAN</th>\n",
       "      <th>CLOSED_DEBT_CREDIT_DIFF_MIN</th>\n",
       "      <th>CLOSED_DEBT_CREDIT_DIFF_MAX</th>\n",
       "      <th>CLOSED_DEBT_CREDIT_DIFF_MEAN</th>\n",
       "      <th>CLOSED_BUREAU_IS_DPD_MEAN</th>\n",
       "      <th>CLOSED_BUREAU_IS_DPD_SUM</th>\n",
       "      <th>CLOSED_BUREAU_IS_DPD_OVER120_MEAN</th>\n",
       "      <th>CLOSED_BUREAU_IS_DPD_OVER120_SUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>85245.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22248.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>69133.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94500.0</td>\n",
       "      <td>94537.8</td>\n",
       "      <td>94518.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146250.0</td>\n",
       "      <td>146250.0</td>\n",
       "      <td>146250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307501</th>\n",
       "      <td>456251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307502</th>\n",
       "      <td>456252</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307503</th>\n",
       "      <td>456253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307504</th>\n",
       "      <td>456254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307505</th>\n",
       "      <td>456255</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22995.0</td>\n",
       "      <td>27472.5</td>\n",
       "      <td>24487.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307506 rows × 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0           100002       1            0             0                0   \n",
       "1           100003       0            1             0                1   \n",
       "2           100004       0            0             1                0   \n",
       "3           100006       0            1             0                0   \n",
       "4           100007       0            0             0                0   \n",
       "...            ...     ...          ...           ...              ...   \n",
       "307501      456251       0            0             0                1   \n",
       "307502      456252       0            1             0                0   \n",
       "307503      456253       0            1             0                0   \n",
       "307504      456254       1            1             0                0   \n",
       "307505      456255       0            1             0                1   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0                  0          202500.0    406597.5      24700.5   \n",
       "1                  0          270000.0   1293502.5      35698.5   \n",
       "2                  0           67500.0    135000.0       6750.0   \n",
       "3                  0          135000.0    312682.5      29686.5   \n",
       "4                  0          121500.0    513000.0      21865.5   \n",
       "...              ...               ...         ...          ...   \n",
       "307501             0          157500.0    254700.0      27558.0   \n",
       "307502             0           72000.0    269550.0      12001.5   \n",
       "307503             0          153000.0    677664.0      29979.0   \n",
       "307504             0          171000.0    370107.0      20205.0   \n",
       "307505             0          157500.0    675000.0      49117.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  ...  CLOSED_BUREAU_CREDIT_DEBT_RATIO_MIN  \\\n",
       "0              351000.0  ...                                  0.0   \n",
       "1             1129500.0  ...                                  0.0   \n",
       "2              135000.0  ...                                  0.0   \n",
       "3              297000.0  ...                                  NaN   \n",
       "4              513000.0  ...                                  0.0   \n",
       "...                 ...  ...                                  ...   \n",
       "307501         225000.0  ...                                  NaN   \n",
       "307502         225000.0  ...                                  NaN   \n",
       "307503         585000.0  ...                                  0.0   \n",
       "307504         319500.0  ...                                  0.0   \n",
       "307505         675000.0  ...                                  0.0   \n",
       "\n",
       "        CLOSED_BUREAU_CREDIT_DEBT_RATIO_MAX  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       NaN   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "307501                                  NaN   \n",
       "307502                                  NaN   \n",
       "307503                                  0.0   \n",
       "307504                                  0.0   \n",
       "307505                                  0.0   \n",
       "\n",
       "        CLOSED_BUREAU_CREDIT_DEBT_RATIO_MEAN  CLOSED_DEBT_CREDIT_DIFF_MIN  \\\n",
       "0                                        0.0                          0.0   \n",
       "1                                        0.0                      22248.0   \n",
       "2                                        0.0                      94500.0   \n",
       "3                                        NaN                          NaN   \n",
       "4                                        0.0                     146250.0   \n",
       "...                                      ...                          ...   \n",
       "307501                                   NaN                          NaN   \n",
       "307502                                   NaN                          NaN   \n",
       "307503                                   0.0                     675000.0   \n",
       "307504                                   0.0                      45000.0   \n",
       "307505                                   0.0                      22995.0   \n",
       "\n",
       "        CLOSED_DEBT_CREDIT_DIFF_MAX  CLOSED_DEBT_CREDIT_DIFF_MEAN  \\\n",
       "0                          135000.0                       85245.0   \n",
       "1                          112500.0                       69133.5   \n",
       "2                           94537.8                       94518.9   \n",
       "3                               NaN                           NaN   \n",
       "4                          146250.0                      146250.0   \n",
       "...                             ...                           ...   \n",
       "307501                          NaN                           NaN   \n",
       "307502                          NaN                           NaN   \n",
       "307503                     675000.0                      675000.0   \n",
       "307504                      45000.0                       45000.0   \n",
       "307505                      27472.5                       24487.5   \n",
       "\n",
       "        CLOSED_BUREAU_IS_DPD_MEAN  CLOSED_BUREAU_IS_DPD_SUM  \\\n",
       "0                             0.0                       0.0   \n",
       "1                             0.0                       0.0   \n",
       "2                             0.0                       0.0   \n",
       "3                             NaN                       NaN   \n",
       "4                             0.0                       0.0   \n",
       "...                           ...                       ...   \n",
       "307501                        NaN                       NaN   \n",
       "307502                        NaN                       NaN   \n",
       "307503                        0.0                       0.0   \n",
       "307504                        0.0                       0.0   \n",
       "307505                        0.0                       0.0   \n",
       "\n",
       "        CLOSED_BUREAU_IS_DPD_OVER120_MEAN  CLOSED_BUREAU_IS_DPD_OVER120_SUM  \n",
       "0                                     0.0                               0.0  \n",
       "1                                     0.0                               0.0  \n",
       "2                                     0.0                               0.0  \n",
       "3                                     NaN                               NaN  \n",
       "4                                     0.0                               0.0  \n",
       "...                                   ...                               ...  \n",
       "307501                                NaN                               NaN  \n",
       "307502                                NaN                               NaN  \n",
       "307503                                0.0                               0.0  \n",
       "307504                                0.0                               0.0  \n",
       "307505                                0.0                               0.0  \n",
       "\n",
       "[307506 rows x 508 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-kinase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-documentation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-crack",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "floral-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "col_num = list(df.select_dtypes('float64').columns)\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "df[col_num] = imp_mean.fit_transform(df[col_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "posted-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = list(df.select_dtypes('int64').columns)\n",
    "imp_meanN = SimpleImputer(missing_values=np.nan, strategy='mean', copy=False)\n",
    "df[col_num] = imp_meanN.fit_transform(df[col_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "capable-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_obj = list(df.select_dtypes('object').columns)\n",
    "imp_cons = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='NonRenseigne')\n",
    "df[col_obj] = imp_cons.fit_transform(df[col_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-novel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
